#' Extract features from Antismash json files
#'
#' @param jsons A character vector of valid filepaths.
#' @param features_types A list of desired features types, by default all.
#'
#' @return A list of list of records.
#' @export
#'
  get_antismash_features <- function(jsons, features_types=NULL){
    fn <- purrr::possibly(get_features_list_,quiet = FALSE)
    purrr::map(jsons, fn,feature_types = features_types,.progress = TRUE)
  }

get_features_list_ <- function(json, feature_types = NULL){
  filter_fn <- function(x) {
    if (is.null(feature_types)){return(TRUE)}
    x$type %in% feature_types
  }
  records <- json |>
    jsonlite::read_json()|>
    purrr::pluck("records")
  contig_accessions <- records |>
    purrr::map(purrr::pluck, "annotations", "accessions",1, .default = "") |>
    as.character() |>
    make.unique()
  names(records) <- contig_accessions
  records |>
    purrr::map(purrr::pluck, "features") |>
    purrr::map(~purrr::keep(., filter_fn)) |>
    purrr::compact()
}

extract_from <- function(x, ...) {
  x |>
    purrr::list_flatten()|>
    purrr::map(purrr::pluck, ..., .default = NA)
}

#' Creates a dataframe with region information from antiSMASH data
#' @param features List object generated by `get_antismash_features`
#' @return A tibble where each where each region is an observation
#' @export
get_antismash_regions <- function(features){
  fn <- purrr::possibly(get_antismash_regions_,quiet = FALSE)
  purrr::map(features, fn) |>
    dplyr::bind_rows(.id = "file")
  }

get_antismash_regions_ <- function(features){
  filter_fn <- function(x) x$type == "region"
  regions <- features |>
    purrr::map(~purrr::keep(., filter_fn))
  if (length(regions)== 0) {return(NULL)}

  region_numbers <- extract_from(
    regions, "qualifiers", "region_number"
  ) |> purrr::list_flatten() |>as.numeric()

  tibble::tibble(
    location = extract_from(regions, "location") |> as.character(),
    type = extract_from(regions, "type") |> as.character(),
    contig_edge = extract_from(
      regions, "qualifiers", "contig_edge"
      ) |> purrr::list_flatten() |> as.logical(),
    product = extract_from(
      regions, "qualifiers", "product"
    ) |> purrr::map(purrr::compose(sort, as.character)) |> as.list(),
    contig = names(product)
  ) |>
    dplyr::mutate(
      bgc_id = paste0(contig, ".region", stringr::str_pad(
        region_numbers, width = 3, pad = '0'))
    )
}


#' Creates a dataframe with module information from antiSMASH data
#' @param features List object generated by `get_antismash_features`
#' @return A tibble where each where each region is an observation
#' @export
get_antismash_modules <- function(features){
  fn <- purrr::possibly(get_antismash_modules_,quiet = FALSE)
  purrr::map(features, fn) |>
    dplyr::bind_rows(.id = "file")
}



get_antismash_modules_ <- function(features){
  filter_fn <- function(x) x$type == "aSModule"
  modules <- features |>
    purrr::map(~purrr::keep(., filter_fn))|>
    purrr::compact()
  qualifiers <- extract_from(modules, "qualifiers")
  tibble::tibble(
    location = extract_from(modules, "location") |>
      as.character(),
    complete = purrr::map(qualifiers, ~ 'complete' %in% names(.)) |>
      as.logical(),
    type = extract_from(modules, "qualifiers", "type") |>
      purrr::list_flatten() |> as.character(),
    iterative = purrr::map(qualifiers, ~ 'iterative' %in% names(.)) |>
      as.logical()
  )
}

#' Extract clustering information from bigscape
#'
#' @param bigscape_dir A valid filepath
#'
#' @return A DataFrame
#' @export
#'
get_bigscape_clustering <- function(bigscape_dir){
  clustering_files <-
    list.files(
      path = bigscape_dir,
      pattern = "\\.tsv$",
      recursive = TRUE,full.names = TRUE
      ) |>
    stringr::str_subset(pattern = "clustering")
  names(clustering_files) <- basename(clustering_files)
  df <- purrr::map(
      clustering_files,
      readr::read_tsv,
      col_types = 'cc',
      ) |>
    dplyr::bind_rows(.id = "table") |>
    dplyr::mutate(
      cutoff = stringr::str_match(.data[["table"]], "clustering_c(.+)\\.tsv")[,2],
      class = stringr::str_match(.data[["table"]], "(^.+?)_clustering")[,2]
    ) |>
    dplyr::select(-dplyr::any_of("table"))

  colnames(df) <- c('bgc_id', 'GCF', 'cutoff', 'class')
  df |>
    dplyr::distinct() |>
    tidyr::pivot_wider(values_from = 'GCF', names_from = 'cutoff', names_prefix = "GCF_c")
}

#' Extract network information from bigscape
#'
#' @param bigscape_dir A valid filepath
#' @param cutoff A numeric value indicating the cutoff.
#'
#' @return
#' @export
#'
get_bigscape_networks <- function(bigscape_dir, cutoff = 0.3){

  pattern <- paste0("_c",format(round(cutoff, 2), nsmall = 2),".network$")

  network_files <-
    list.files(
      path = bigscape_dir,
      pattern = pattern,
      recursive = TRUE,
      full.names = TRUE)
  names(network_files) <- network_files
  x <- purrr::map(
    network_files, readr::read_tsv,
    col_select = 1:4,col_types = 'ccdd',
  ) |>
    dplyr::bind_rows(.id = "table") |>
    dplyr::mutate(
      cutoff = as.numeric(
        stringr::str_match(.data[["table"]], "_c(.+)\\.network")[,2]
        ),
      class = stringr::str_match(.data[["table"]], "(^.+?)_c")[,2]) |>
    dplyr::select(-table)
  colnames(x) <- c('bgc_id_1', 'bgc_id_2', 'raw_distance', 'squared_similarity', 'cutoff', 'class')
  dplyr::distinct(x)
}

